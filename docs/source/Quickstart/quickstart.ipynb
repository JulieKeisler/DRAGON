{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../../..\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "\n",
    "In this tutorial, for computation time issues (e.g. training a neural network is time consumming), we will use a small time series forecasting task from the **GluonTS** package, called *m1_monthly*.\n",
    "\n",
    "\n",
    "More applications are detailed here: [Examples](../Examples/index.rst)\n",
    "\n",
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dragon.experiments.monash_archive.dataset import gluonts_dataset\n",
    "from dragon.experiments.monash_archive.datasets_configs import m1_monthly_config\n",
    "\n",
    "# Remove unnecessary logs from imported packages\n",
    "import logging\n",
    "\n",
    "log_gluonts = logging.getLogger(\"gluonts\")\n",
    "log_gluonts.setLevel('CRITICAL')\n",
    "log_mxnet = logging.getLogger(\"pytorch_lightning\")\n",
    "log_mxnet.setLevel('CRITICAL')\n",
    "log_dragon = logging.getLogger(\"\")\n",
    "log_dragon.setLevel('CRITICAL')\n",
    "\n",
    "train_ds, test_ds, config = gluonts_dataset(m1_monthly_config)\n",
    "config['SaveDir'] = config['PathName'] + \"_\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Loss Function\n",
    "\n",
    "The `loss function` measures how well our Deep Neural Network performed on the considered task. This function should handle the DNN training procedure as well as the metric computation on the validation set. The user is required to define a model, a training and a testing procedure.\n",
    "\n",
    "Then, we use a wrapping function called `zellij.core.Loss` from **Zellij**. By setting the argument `MPI` to **True**, one can use the distributed version of the `Loss` object.\n",
    "\n",
    "\n",
    "##### DNN definition\n",
    "\n",
    "The class `dragon.experiments.monash_archive.training.GluontsNet`, designed specially for the **GluonTS** forecasting datasets handles the DNN creation, its training and testing procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dragon.experiments.monash_archive.training import GluontsNet\n",
    "m1_monthly_config['NumEpochs'] = 20\n",
    "model = GluontsNet(train_ds, test_ds, m1_monthly_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from zellij.core import Loss    \n",
    "\n",
    "loss = Loss(MPI=False, verbose=False, save=True)(model.get_nn_forecast)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Space definition\n",
    "\n",
    "To define a searchspace one need to define variables `var`, which would be optimized.\n",
    "\n",
    "The DNN are modelized by **AdjMatrix** (`dragon.search_space.dags.AdjMatrixVariable`). They are parametrized by a set of candidate operations. Each candidate operations are modelized by an **ArrayVar** (`zellij.core.ArrayVar`) containing the operation name and the associated *hyperparameters*. They can be of type:\n",
    "\n",
    "* **Floats**: `zellij.core.FloatVar`, e.g: learning rate, dropout rate, etc.\n",
    "* **Integers**: `zellij.core.IntVar`, e.g: output dimension, kernel size, etc.\n",
    "* **Categorical**: `zellij.core.CatVar`, e.g: activation function, pooling type, etc.\n",
    "\n",
    "Typical candidate operations variables are already defined within the package: `dragon.search_space.variables`. They are based on `nn.Module` defined in the `dragon.search_space.bricks` repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zellij.core.variables import CatVar, ArrayVar, DynamicBlock\n",
    "from zellij.utils.neighborhoods import ArrayInterval, DynamicBlockInterval\n",
    "\n",
    "from dragon.search_algorithm.neighborhoods import LayersInterval, AdjMatrixInterval\n",
    "from dragon.search_space.dags import AdjMatrixVariable\n",
    "from dragon.search_space.variables import unitary_var, mlp_var, activation_var, create_int_var\n",
    "\n",
    "# We define the candidate operations for each nodes in the graph. Here we only consider multi-layers perceptron and identity operations.\n",
    "def operations_var(label, shape, size):\n",
    "    return DynamicBlock(\n",
    "        label,\n",
    "        CatVar(\n",
    "            label + \"Candidates\",\n",
    "            [\n",
    "                unitary_var(label + \" Unitary\"),\n",
    "                mlp_var(label + \" MLP\"),\n",
    "            ],\n",
    "            neighbor=LayersInterval([2, 1]),\n",
    "        ),\n",
    "        size,\n",
    "        neighbor=DynamicBlockInterval(neighborhood=2),\n",
    "    )\n",
    "\n",
    "# We define the serach space, a graph handling one-dimensional data, and the final activation function before the prediction.\n",
    "def NN_monash_var(label=\"Neural Network\", shape=1000, size=10):\n",
    "    NeuralNetwork = ArrayVar(\n",
    "        AdjMatrixVariable(\n",
    "            \"Cell\",\n",
    "            operations_var(\"Feed Cell\", shape, size),\n",
    "            neighbor=AdjMatrixInterval()\n",
    "        ),\n",
    "        activation_var(\"NN Activation\"),\n",
    "        create_int_var(\"Seed\", None, 0, 10000),\n",
    "        label=label,\n",
    "        neighbor=ArrayInterval(),\n",
    "    )\n",
    "    return NeuralNetwork\n",
    "\n",
    "sp = NN_monash_var(shape=m1_monthly_config[\"Lag\"], size=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your search space is defined, you can draw random points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First random point:  [NODES: [['Input'], ['concat', 'MLP', 301, 'swish'], ['mul', 'MLP', 164, 'id']] | MATRIX:[[0, 1, 1], [0, 0, 1], [0, 0, 0]], 'sigmoid', 5684]\n",
      "Second random point:  [NODES: [['Input'], ['mul', 'Identity'], ['mul', 'MLP', 417, 'softmax']] | MATRIX:[[0, 1, 0], [0, 0, 1], [0, 0, 0]], 'gelu', 8854]\n"
     ]
    }
   ],
   "source": [
    "p1,p2 = sp.random(), sp.random()\n",
    "print(\"First random point: \", p1)\n",
    "print(\"Second random point: \", p2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the loss function on the search space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 5684\n",
      "Global seed set to 8854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best solution found:\n",
      "  [NODES: [['Input'], ['concat', 'MLP', 301, 'swish'], ['mul', 'MLP', 164, 'id']] | MATRIX:[[0, 1, 1], [0, 0, 1], [0, 0, 0]], 'sigmoid', 5684] \n",
      "       = 1.280236\n",
      "Number of evaluations:2\n",
      "All evaluated solutions:[[NODES: [['Input'], ['concat', 'MLP', 301, 'swish'], ['mul', 'MLP', 164, 'id']] | MATRIX:[[0, 1, 1], [0, 0, 1], [0, 0, 0]], 'sigmoid', 5684], [NODES: [['Input'], ['mul', 'Identity'], ['mul', 'MLP', 417, 'softmax']] | MATRIX:[[0, 1, 0], [0, 0, 1], [0, 0, 0]], 'gelu', 8854]]\n",
      "All loss values:[1.280236, 1.40858]\n"
     ]
    }
   ],
   "source": [
    "scores = loss([p1, p2])\n",
    "print(\"\\n\")\n",
    "print(f\"Best solution found:\\n  {loss.best_point} \\n       = {loss.best_score}\")\n",
    "print(f\"Number of evaluations:{loss.calls}\")\n",
    "print(f\"All evaluated solutions:{loss.all_solutions}\")\n",
    "print(f\"All loss values:{loss.all_scores}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing an optimization strategy\n",
    "\n",
    "To ease the use of several metaheuristics, the user can directly use the function `evodags.search_algorithm.pb_configuration.problem_configuration` to define its search strategy.\n",
    "\n",
    "In our case we will use an Evolutionary Algorithm, we set the *MetaHeuristic* entry from the config to **GA**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".enlighten-fg-white {\n",
       "  color: #e5e5e5;\n",
       "}\n",
       ".enlighten-fg-cyan {\n",
       "  color: #00cdcd;\n",
       "}\n",
       ".enlighten-fg-orange {\n",
       "  color: #ffa500;\n",
       "}\n",
       "</style>\n",
       "<div class=\"enlighten\">\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre>Improvements 1 solutions [02:32, 0.01 solutions/s]                                                  </pre>\n",
       "  </div>\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre>Loss calls   0%|<span class=\"enlighten-fg-white\">                                     </span>| Pending:      0 Explor:      8 Exploi:      0</pre>\n",
       "  </div>\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre>   Genetic_algorithm 100%|<span class=\"enlighten-fg-white\">████████████████████████████████████████████████████████████████████████</span>| </pre>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 7546\n",
      "Global seed set to 7965\n",
      "Global seed set to 436\n",
      "Global seed set to 1612\n",
      "Global seed set to 8909\n",
      "Global seed set to 3208\n",
      "Global seed set to 3039\n",
      "Global seed set to 8909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution found:\n",
      "f([[NODES: [['Input'], ['mul', 'Identity'], ['mul', 'Identity']] | MATRIX:[[0, 1, 1], [0, 0, 1], [0, 0, 0]], 'gelu', 7546]]) = [1.217747],\n",
      "computation time: 152.39 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from dragon.search_algorithm.pb_configuration import problem_configuration\n",
    "  \n",
    "exp_config = {\n",
    "    \"MetaHeuristic\": \"GA\",\n",
    "    \"Generations\": 2,\n",
    "    \"PopSize\": 4,\n",
    "    \"MutationRate\": 0.7,\n",
    "    \"TournamentRate\": 10,\n",
    "    \"ElitismRate\": 0.1,\n",
    "    \"RandomRate\": 0.1,\n",
    "    \"Neighborhood\": \"Full\"\n",
    "}\n",
    "\n",
    "_, search_algorithm = problem_configuration(exp_config, sp, loss)\n",
    "\n",
    "start_time = time.time()\n",
    "best, score = search_algorithm.run()\n",
    "end_time = time.time() - start_time\n",
    "print(f\"Best solution found:\\nf({best}) = {score},\\ncomputation time: {np.round(end_time,2)} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
