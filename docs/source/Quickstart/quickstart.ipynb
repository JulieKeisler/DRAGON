{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../../..\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "\n",
    "In this tutorial, for computation time issues (e.g. training a neural network is time consumming), we will use a small time series forecasting task from the **GluonTS** package, called *m1_monthly*.\n",
    "\n",
    "\n",
    "More applications are detailed here: [Examples](../Examples/index.rst)\n",
    "\n",
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-13 11:54:34,035 | INFO | To use MPILoss object you need to install mpi4py and an MPI distribution\n",
      "    You can use: pip install zellij[MPI]\n",
      "2023-10-13 11:54:34,190 | INFO | Started loading m1_monthly\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dragon.experiments.monash_archive.dataset import gluonts_dataset\n",
    "from dragon.experiments.monash_archive.datasets_configs import m1_monthly_config\n",
    "\n",
    "train_ds, test_ds, config = gluonts_dataset(m1_monthly_config)\n",
    "config['SaveDir'] = config['PathName'] + \"_\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Loss Function\n",
    "\n",
    "The `loss function` measures how well our Deep Neural Network performed on the considered task. This function should handle the DNN training procedure as well as the metric computation on the validation set. The user is required to define a model, a training and a testing procedure.\n",
    "\n",
    "Then, we use a wrapping function called `zellij.core.Loss` from **Zellij**. By setting the argument `MPI` to **True**, one can use the distributed version of the `Loss` object.\n",
    "\n",
    "\n",
    "##### DNN definition\n",
    "\n",
    "The class `dragon.experiments.monash_archive.training.GluontsNet`, designed specially for the **GluonTS** forecasting datasets handles the DNN creation, its training and testing procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dragon.experiments.monash_archive.training import GluontsNet\n",
    "m1_monthly_config['NumEpochs'] = 20\n",
    "model = GluontsNet(train_ds, test_ds, m1_monthly_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from zellij.core import Loss    \n",
    "\n",
    "loss = Loss(MPI=False, verbose=False, save=True)(model.get_nn_forecast)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Space definition\n",
    "\n",
    "To define a searchspace one need to define variables `var`, which would be optimized.\n",
    "\n",
    "The DNN are modelized by **AdjMatrix** (`dragon.search_space.dags.AdjMatrixVariable`). They are parametrized by a set of candidate operations. Each candidate operations are modelized by an **ArrayVar** (`zellij.core.ArrayVar`) containing the operation name and the associated *hyperparameters*. They can be of type:\n",
    "\n",
    "* **Floats**: `zellij.core.FloatVar`, e.g: learning rate, dropout rate, etc.\n",
    "* **Integers**: `zellij.core.IntVar`, e.g: output dimension, kernel size, etc.\n",
    "* **Categorical**: `zellij.core.CatVar`, e.g: activation function, pooling type, etc.\n",
    "\n",
    "Typical candidate operations variables are already defined within the package: `dragon.search_space.variables`. They are based on `nn.Module` defined in the `dragon.search_space.bricks` repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zellij.core.variables import CatVar, ArrayVar, DynamicBlock\n",
    "from zellij.utils.neighborhoods import ArrayInterval, DynamicBlockInterval\n",
    "\n",
    "from dragon.search_algorithm.neighborhoods import LayersInterval, AdjMatrixInterval\n",
    "from dragon.search_space.dags import AdjMatrixVariable\n",
    "from dragon.search_space.variables import unitary_var, mlp_var, activation_var, create_int_var\n",
    "\n",
    "# We define the candidate operations for each nodes in the graph. Here we only consider multi-layers perceptron and identity operations.\n",
    "def operations_var(label, shape, size):\n",
    "    return DynamicBlock(\n",
    "        label,\n",
    "        CatVar(\n",
    "            label + \"Candidates\",\n",
    "            [\n",
    "                unitary_var(label + \" Unitary\"),\n",
    "                mlp_var(label + \" MLP\"),\n",
    "            ],\n",
    "            neighbor=LayersInterval([2, 1]),\n",
    "        ),\n",
    "        size,\n",
    "        neighbor=DynamicBlockInterval(neighborhood=2),\n",
    "    )\n",
    "\n",
    "# We define the serach space, a graph handling one-dimensional data, and the final activation function before the prediction.\n",
    "def NN_monash_var(label=\"Neural Network\", shape=1000, size=10):\n",
    "    NeuralNetwork = ArrayVar(\n",
    "        AdjMatrixVariable(\n",
    "            \"Cell\",\n",
    "            operations_var(\"Feed Cell\", shape, size),\n",
    "            neighbor=AdjMatrixInterval()\n",
    "        ),\n",
    "        activation_var(\"NN Activation\"),\n",
    "        create_int_var(\"Seed\", None, 0, 10000),\n",
    "        label=label,\n",
    "        neighbor=ArrayInterval(),\n",
    "    )\n",
    "    return NeuralNetwork\n",
    "\n",
    "sp = NN_monash_var(shape=m1_monthly_config[\"Lag\"], size=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your search space is defined, you can draw random points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First random point:  [NODES: [['Input'], ['concat', 'MLP', 386, 'swish']] | MATRIX:[[0, 1], [0, 0]], 'sigmoid', 2618]\n",
      "Second random point:  [NODES: [['Input'], ['add', 'Identity'], ['concat', 'Identity']] | MATRIX:[[0, 1, 1], [0, 0, 1], [0, 0, 0]], 'leaky_relu', 3127]\n"
     ]
    }
   ],
   "source": [
    "p1,p2 = sp.random(), sp.random()\n",
    "print(\"First random point: \", p1)\n",
    "print(\"Second random point: \", p2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the loss function on the search space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2618\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scores \u001b[39m=\u001b[39m loss([p1, p2])\n",
      "File \u001b[0;32m~/miniconda3/envs/dragon_env/lib/python3.9/site-packages/zellij/core/loss_func.py:838\u001b[0m, in \u001b[0;36mSerialLoss.__call__\u001b[0;34m(self, X, **kwargs)\u001b[0m\n\u001b[1;32m    834\u001b[0m     outputs, trained_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_return(\n\u001b[1;32m    835\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_kwargs)\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 838\u001b[0m     outputs, trained_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_return(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x))\n\u001b[1;32m    839\u001b[0m score, others \u001b[39m=\u001b[39m outputs[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m], outputs\n\u001b[1;32m    841\u001b[0m res\u001b[39m.\u001b[39mappend(score)\n",
      "File \u001b[0;32m~/Documents/CIFRE/Code/EvoDagsAutoDL/lib/dragon/experiments/monash_archive/training.py:56\u001b[0m, in \u001b[0;36mGluontsNet.get_nn_forecast\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     39\u001b[0m estimator \u001b[39m=\u001b[39m FeedCellEstimator(\n\u001b[1;32m     40\u001b[0m     model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mModel\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     41\u001b[0m     lightning_module\u001b[39m=\u001b[39mFeedCellLightningModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m     53\u001b[0m )\n\u001b[1;32m     55\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     predictor \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39;49mtrain(training_data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_ds, enable_progress_bar\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     57\u001b[0m     forecast_it, ts_it \u001b[39m=\u001b[39m make_evaluation_predictions(dataset\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_ds, predictor\u001b[39m=\u001b[39mpredictor, num_samples\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m     59\u001b[0m     \u001b[39m# Time series predictions\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dragon_env/lib/python3.9/site-packages/gluonts/torch/model/estimator.py:237\u001b[0m, in \u001b[0;36mPyTorchLightningEstimator.train\u001b[0;34m(self, training_data, validation_data, shuffle_buffer_length, cache_data, ckpt_path, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\n\u001b[1;32m    229\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    230\u001b[0m     training_data: Dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    236\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PyTorchPredictor:\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_model(\n\u001b[1;32m    238\u001b[0m         training_data,\n\u001b[1;32m    239\u001b[0m         validation_data,\n\u001b[1;32m    240\u001b[0m         shuffle_buffer_length\u001b[39m=\u001b[39;49mshuffle_buffer_length,\n\u001b[1;32m    241\u001b[0m         cache_data\u001b[39m=\u001b[39;49mcache_data,\n\u001b[1;32m    242\u001b[0m         ckpt_path\u001b[39m=\u001b[39;49mckpt_path,\n\u001b[1;32m    243\u001b[0m     )\u001b[39m.\u001b[39mpredictor\n",
      "File \u001b[0;32m~/miniconda3/envs/dragon_env/lib/python3.9/site-packages/gluonts/torch/model/estimator.py:205\u001b[0m, in \u001b[0;36mPyTorchLightningEstimator.train_model\u001b[0;34m(self, training_data, validation_data, from_predictor, shuffle_buffer_length, cache_data, ckpt_path, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m trainer_kwargs \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer_kwargs, \u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks}\n\u001b[1;32m    203\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrainer_kwargs)\n\u001b[0;32m--> 205\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    206\u001b[0m     model\u001b[39m=\u001b[39;49mtraining_network,\n\u001b[1;32m    207\u001b[0m     train_dataloaders\u001b[39m=\u001b[39;49mtraining_data_loader,\n\u001b[1;32m    208\u001b[0m     val_dataloaders\u001b[39m=\u001b[39;49mvalidation_data_loader,\n\u001b[1;32m    209\u001b[0m     ckpt_path\u001b[39m=\u001b[39;49mckpt_path,\n\u001b[1;32m    210\u001b[0m )\n\u001b[1;32m    212\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoading best model from \u001b[39m\u001b[39m{\u001b[39;00mcheckpoint\u001b[39m.\u001b[39mbest_model_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    213\u001b[0m best_model \u001b[39m=\u001b[39m training_network\u001b[39m.\u001b[39mload_from_checkpoint(\n\u001b[1;32m    214\u001b[0m     checkpoint\u001b[39m.\u001b[39mbest_model_path\n\u001b[1;32m    215\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/dragon_env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:532\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m    531\u001b[0m _verify_strategy_supports_compile(model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy)\n\u001b[0;32m--> 532\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    533\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    534\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/dragon_env/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/dragon_env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:571\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[1;32m    562\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    565\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    566\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    567\u001b[0m     ckpt_path,\n\u001b[1;32m    568\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    570\u001b[0m )\n\u001b[0;32m--> 571\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    574\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dragon_env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:938\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[39m# SET UP THE TRAINER\u001b[39;00m\n\u001b[1;32m    936\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    937\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: setting up strategy environment\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 938\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49msetup_environment()\n\u001b[1;32m    939\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__setup_profiler()\n\u001b[1;32m    941\u001b[0m call\u001b[39m.\u001b[39m_call_setup_hook(\u001b[39mself\u001b[39m)  \u001b[39m# allow user to setup lightning_module in accelerator environment\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dragon_env/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py:129\u001b[0m, in \u001b[0;36mStrategy.setup_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Setup any processes or distributed connections.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \n\u001b[1;32m    124\u001b[0m \u001b[39mThis is called before the LightningModule/DataModule setup hook which allows the user to access the accelerator\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39menvironment before setup is complete.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[1;32m    127\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49msetup_device(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/dragon_env/lib/python3.9/site-packages/pytorch_lightning/accelerators/cuda.py:44\u001b[0m, in \u001b[0;36mCUDAAccelerator.setup_device\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mif\u001b[39;00m device\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     43\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDevice should be GPU, got \u001b[39m\u001b[39m{\u001b[39;00mdevice\u001b[39m}\u001b[39;00m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m _check_cuda_matmul_precision(device)\n\u001b[1;32m     45\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mset_device(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/dragon_env/lib/python3.9/site-packages/lightning_fabric/accelerators/cuda.py:349\u001b[0m, in \u001b[0;36m_check_cuda_matmul_precision\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _TORCH_GREATER_EQUAL_1_12:\n\u001b[1;32m    347\u001b[0m     \u001b[39m# before 1.12, tf32 was used by default\u001b[39;00m\n\u001b[1;32m    348\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m major, _ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mget_device_capability(device)\n\u001b[1;32m    350\u001b[0m ampere_or_later \u001b[39m=\u001b[39m major \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m8\u001b[39m  \u001b[39m# Ampere and later leverage tensor cores, where this setting becomes useful\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ampere_or_later:\n",
      "File \u001b[0;32m~/miniconda3/envs/dragon_env/lib/python3.9/site-packages/torch/cuda/__init__.py:435\u001b[0m, in \u001b[0;36mget_device_capability\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_device_capability\u001b[39m(device: Optional[_device_t] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[\u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m]:\n\u001b[1;32m    423\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Gets the cuda capability of a device.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \n\u001b[1;32m    425\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39m        tuple(int, int): the major and minor cuda capability of the device\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 435\u001b[0m     prop \u001b[39m=\u001b[39m get_device_properties(device)\n\u001b[1;32m    436\u001b[0m     \u001b[39mreturn\u001b[39;00m prop\u001b[39m.\u001b[39mmajor, prop\u001b[39m.\u001b[39mminor\n",
      "File \u001b[0;32m~/miniconda3/envs/dragon_env/lib/python3.9/site-packages/torch/cuda/__init__.py:449\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_device_properties\u001b[39m(device: _device_t) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m _CudaDeviceProperties:\n\u001b[1;32m    440\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Gets the properties of a device.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \n\u001b[1;32m    442\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m     _lazy_init()  \u001b[39m# will define _get_device_properties\u001b[39;00m\n\u001b[1;32m    450\u001b[0m     device \u001b[39m=\u001b[39m _get_device_index(device, optional\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    451\u001b[0m     \u001b[39mif\u001b[39;00m device \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count():\n",
      "File \u001b[0;32m~/miniconda3/envs/dragon_env/lib/python3.9/site-packages/torch/cuda/__init__.py:298\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron:\n\u001b[1;32m    297\u001b[0m     os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLAZY\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 298\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_init()\n\u001b[1;32m    299\u001b[0m \u001b[39m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[39m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[39m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    302\u001b[0m _tls\u001b[39m.\u001b[39mis_initializing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "scores = loss([p1, p2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config['NumEpochs']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
